{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Milestone 3: Genre Prediction Using Standard ML Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import RandomForestClassifier as RFC\n",
    "from sklearn.ensemble import AdaBoostClassifier as AdaBoost\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import hamming_loss\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from stop_words import get_stop_words\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from gensim import corpora, models\n",
    "import gensim\n",
    "\n",
    "import string\n",
    "import time\n",
    "from datetime import datetime\n",
    "from __future__ import division"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's begin by loading and examining our raw dataset, containing data obtained through the TMDB API and saved previously as a CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IOError",
     "evalue": "File features_V1.csv does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-68eea3862852>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfeatures\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'features_V1.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32mC:\\Users\\Joeseph\\Anaconda2\\lib\\site-packages\\pandas\\io\\parsers.pyc\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    560\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    561\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 562\u001b[0;31m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    563\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Joeseph\\Anaconda2\\lib\\site-packages\\pandas\\io\\parsers.pyc\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    313\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 315\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    316\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mchunksize\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Joeseph\\Anaconda2\\lib\\site-packages\\pandas\\io\\parsers.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    643\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    644\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 645\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    646\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    647\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Joeseph\\Anaconda2\\lib\\site-packages\\pandas\\io\\parsers.pyc\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m    797\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'c'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    798\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'c'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 799\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    800\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    801\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'python'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Joeseph\\Anaconda2\\lib\\site-packages\\pandas\\io\\parsers.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1211\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'allow_leading_cols'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex_col\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1212\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1213\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_parser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1214\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1215\u001b[0m         \u001b[1;31m# XXX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas\\parser.pyx\u001b[0m in \u001b[0;36mpandas.parser.TextReader.__cinit__ (pandas\\parser.c:3427)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas\\parser.pyx\u001b[0m in \u001b[0;36mpandas.parser.TextReader._setup_parser_source (pandas\\parser.c:6861)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mIOError\u001b[0m: File features_V1.csv does not exist"
     ]
    }
   ],
   "source": [
    "%cd ./Train_Data_Version_1/\n",
    "features = pd.read_csv('features_V1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>imdb_id</th>\n",
       "      <th>title</th>\n",
       "      <th>original_title</th>\n",
       "      <th>release_date</th>\n",
       "      <th>overview</th>\n",
       "      <th>tagline</th>\n",
       "      <th>budget</th>\n",
       "      <th>revenue</th>\n",
       "      <th>popularity</th>\n",
       "      <th>...</th>\n",
       "      <th>spoken_languages_ur</th>\n",
       "      <th>spoken_languages_uz</th>\n",
       "      <th>spoken_languages_vi</th>\n",
       "      <th>spoken_languages_wo</th>\n",
       "      <th>spoken_languages_xh</th>\n",
       "      <th>spoken_languages_xx</th>\n",
       "      <th>spoken_languages_yi</th>\n",
       "      <th>spoken_languages_za</th>\n",
       "      <th>spoken_languages_zh</th>\n",
       "      <th>spoken_languages_zu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10895</td>\n",
       "      <td>tt0032910</td>\n",
       "      <td>Pinocchio</td>\n",
       "      <td>Pinocchio</td>\n",
       "      <td>1940-02-23</td>\n",
       "      <td>Lonely toymaker Geppetto has his wishes answer...</td>\n",
       "      <td>For anyone who has ever wished upon a star.</td>\n",
       "      <td>2600000</td>\n",
       "      <td>84300000</td>\n",
       "      <td>2.418732</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>223</td>\n",
       "      <td>tt0032976</td>\n",
       "      <td>Rebecca</td>\n",
       "      <td>Rebecca</td>\n",
       "      <td>1940-04-12</td>\n",
       "      <td>A self-conscious bride is tormented by the mem...</td>\n",
       "      <td>The shadow of this woman darkened their love.</td>\n",
       "      <td>1288000</td>\n",
       "      <td>6000000</td>\n",
       "      <td>1.583448</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>756</td>\n",
       "      <td>tt0032455</td>\n",
       "      <td>Fantasia</td>\n",
       "      <td>Fantasia</td>\n",
       "      <td>1940-11-13</td>\n",
       "      <td>Fantasia is the adventurous 1940 experiment fr...</td>\n",
       "      <td>Hear the pictures! See the music!</td>\n",
       "      <td>2280000</td>\n",
       "      <td>83320000</td>\n",
       "      <td>1.498824</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>981</td>\n",
       "      <td>tt0032904</td>\n",
       "      <td>The Philadelphia Story</td>\n",
       "      <td>The Philadelphia Story</td>\n",
       "      <td>1940-12-01</td>\n",
       "      <td>Philadelphia heiress Tracy Lord throws out her...</td>\n",
       "      <td>Broadway's howling year-run comedy hit of the ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.113673</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>914</td>\n",
       "      <td>tt0032553</td>\n",
       "      <td>The Great Dictator</td>\n",
       "      <td>The Great Dictator</td>\n",
       "      <td>1940-10-15</td>\n",
       "      <td>Dictator Adenoid Hynkel tries to expand his em...</td>\n",
       "      <td>Once again - the whole world laughs!</td>\n",
       "      <td>2000000</td>\n",
       "      <td>11000000</td>\n",
       "      <td>1.005436</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 521 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id    imdb_id                   title          original_title  \\\n",
       "0  10895  tt0032910               Pinocchio               Pinocchio   \n",
       "1    223  tt0032976                 Rebecca                 Rebecca   \n",
       "2    756  tt0032455                Fantasia                Fantasia   \n",
       "3    981  tt0032904  The Philadelphia Story  The Philadelphia Story   \n",
       "4    914  tt0032553      The Great Dictator      The Great Dictator   \n",
       "\n",
       "  release_date                                           overview  \\\n",
       "0   1940-02-23  Lonely toymaker Geppetto has his wishes answer...   \n",
       "1   1940-04-12  A self-conscious bride is tormented by the mem...   \n",
       "2   1940-11-13  Fantasia is the adventurous 1940 experiment fr...   \n",
       "3   1940-12-01  Philadelphia heiress Tracy Lord throws out her...   \n",
       "4   1940-10-15  Dictator Adenoid Hynkel tries to expand his em...   \n",
       "\n",
       "                                             tagline   budget   revenue  \\\n",
       "0        For anyone who has ever wished upon a star.  2600000  84300000   \n",
       "1      The shadow of this woman darkened their love.  1288000   6000000   \n",
       "2                  Hear the pictures! See the music!  2280000  83320000   \n",
       "3  Broadway's howling year-run comedy hit of the ...        0         0   \n",
       "4               Once again - the whole world laughs!  2000000  11000000   \n",
       "\n",
       "   popularity         ...           spoken_languages_ur  spoken_languages_uz  \\\n",
       "0    2.418732         ...                             0                    0   \n",
       "1    1.583448         ...                             0                    0   \n",
       "2    1.498824         ...                             0                    0   \n",
       "3    1.113673         ...                             0                    0   \n",
       "4    1.005436         ...                             0                    0   \n",
       "\n",
       "  spoken_languages_vi  spoken_languages_wo spoken_languages_xh  \\\n",
       "0                   0                    0                   0   \n",
       "1                   0                    0                   0   \n",
       "2                   0                    0                   0   \n",
       "3                   0                    0                   0   \n",
       "4                   0                    0                   0   \n",
       "\n",
       "   spoken_languages_xx  spoken_languages_yi  spoken_languages_za  \\\n",
       "0                    0                    0                    0   \n",
       "1                    0                    0                    0   \n",
       "2                    0                    0                    0   \n",
       "3                    0                    0                    0   \n",
       "4                    0                    0                    0   \n",
       "\n",
       "   spoken_languages_zh  spoken_languages_zu  \n",
       "0                    0                    0  \n",
       "1                    0                    0  \n",
       "2                    0                    0  \n",
       "3                    0                    0  \n",
       "4                    0                    0  \n",
       "\n",
       "[5 rows x 521 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we'll load our previously dummy-coded genre labels and verify they look as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels = pd.read_csv('multilabels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Action</th>\n",
       "      <th>Drama</th>\n",
       "      <th>Comedy</th>\n",
       "      <th>Family</th>\n",
       "      <th>Romance</th>\n",
       "      <th>Documentary</th>\n",
       "      <th>Horror</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Action  Drama  Comedy  Family  Romance  Documentary  Horror\n",
       "0       0      0       0       1        0            0       0\n",
       "1       1      1       0       0        1            0       0\n",
       "2       1      1       0       1        0            0       0\n",
       "3       0      0       1       0        1            0       0\n",
       "4       0      0       1       0        0            0       0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we begin preparing the data for model fitting.  The first step in this process is to remove or reformat features that are not suitable, i.e. numeric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>release_date</th>\n",
       "      <th>budget</th>\n",
       "      <th>revenue</th>\n",
       "      <th>popularity</th>\n",
       "      <th>vote_count</th>\n",
       "      <th>vote_average</th>\n",
       "      <th>runtime</th>\n",
       "      <th>adult</th>\n",
       "      <th>n_actors</th>\n",
       "      <th>n_crew</th>\n",
       "      <th>...</th>\n",
       "      <th>spoken_languages_ur</th>\n",
       "      <th>spoken_languages_uz</th>\n",
       "      <th>spoken_languages_vi</th>\n",
       "      <th>spoken_languages_wo</th>\n",
       "      <th>spoken_languages_xh</th>\n",
       "      <th>spoken_languages_xx</th>\n",
       "      <th>spoken_languages_yi</th>\n",
       "      <th>spoken_languages_za</th>\n",
       "      <th>spoken_languages_zh</th>\n",
       "      <th>spoken_languages_zu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1940-02-23</td>\n",
       "      <td>2600000</td>\n",
       "      <td>84300000</td>\n",
       "      <td>2.418732</td>\n",
       "      <td>933</td>\n",
       "      <td>6.8</td>\n",
       "      <td>88.0</td>\n",
       "      <td>False</td>\n",
       "      <td>12.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1940-04-12</td>\n",
       "      <td>1288000</td>\n",
       "      <td>6000000</td>\n",
       "      <td>1.583448</td>\n",
       "      <td>271</td>\n",
       "      <td>7.6</td>\n",
       "      <td>130.0</td>\n",
       "      <td>False</td>\n",
       "      <td>25.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1940-11-13</td>\n",
       "      <td>2280000</td>\n",
       "      <td>83320000</td>\n",
       "      <td>1.498824</td>\n",
       "      <td>615</td>\n",
       "      <td>7.1</td>\n",
       "      <td>124.0</td>\n",
       "      <td>False</td>\n",
       "      <td>7.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1940-12-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.113673</td>\n",
       "      <td>160</td>\n",
       "      <td>7.6</td>\n",
       "      <td>112.0</td>\n",
       "      <td>False</td>\n",
       "      <td>28.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1940-10-15</td>\n",
       "      <td>2000000</td>\n",
       "      <td>11000000</td>\n",
       "      <td>1.005436</td>\n",
       "      <td>563</td>\n",
       "      <td>8.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>False</td>\n",
       "      <td>59.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 514 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  release_date   budget   revenue  popularity  vote_count  vote_average  \\\n",
       "0   1940-02-23  2600000  84300000    2.418732         933           6.8   \n",
       "1   1940-04-12  1288000   6000000    1.583448         271           7.6   \n",
       "2   1940-11-13  2280000  83320000    1.498824         615           7.1   \n",
       "3   1940-12-01        0         0    1.113673         160           7.6   \n",
       "4   1940-10-15  2000000  11000000    1.005436         563           8.0   \n",
       "\n",
       "   runtime  adult  n_actors  n_crew         ...           spoken_languages_ur  \\\n",
       "0     88.0  False      12.0    75.0         ...                             0   \n",
       "1    130.0  False      25.0    37.0         ...                             0   \n",
       "2    124.0  False       7.0    24.0         ...                             0   \n",
       "3    112.0  False      28.0    13.0         ...                             0   \n",
       "4    125.0  False      59.0    22.0         ...                             0   \n",
       "\n",
       "   spoken_languages_uz  spoken_languages_vi  spoken_languages_wo  \\\n",
       "0                    0                    0                    0   \n",
       "1                    0                    0                    0   \n",
       "2                    0                    0                    0   \n",
       "3                    0                    0                    0   \n",
       "4                    0                    0                    0   \n",
       "\n",
       "   spoken_languages_xh  spoken_languages_xx  spoken_languages_yi  \\\n",
       "0                    0                    0                    0   \n",
       "1                    0                    0                    0   \n",
       "2                    0                    0                    0   \n",
       "3                    0                    0                    0   \n",
       "4                    0                    0                    0   \n",
       "\n",
       "   spoken_languages_za  spoken_languages_zh  spoken_languages_zu  \n",
       "0                    0                    0                    0  \n",
       "1                    0                    0                    0  \n",
       "2                    0                    0                    0  \n",
       "3                    0                    0                    0  \n",
       "4                    0                    0                    0  \n",
       "\n",
       "[5 rows x 514 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#delete text only data\n",
    "features = features.drop(features.columns[[0, 1, 2, 3, 5, 6, 12]], axis=1)\n",
    "features.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>release_date</th>\n",
       "      <th>budget</th>\n",
       "      <th>revenue</th>\n",
       "      <th>popularity</th>\n",
       "      <th>vote_count</th>\n",
       "      <th>vote_average</th>\n",
       "      <th>runtime</th>\n",
       "      <th>adult</th>\n",
       "      <th>n_actors</th>\n",
       "      <th>n_crew</th>\n",
       "      <th>...</th>\n",
       "      <th>spoken_languages_ur</th>\n",
       "      <th>spoken_languages_uz</th>\n",
       "      <th>spoken_languages_vi</th>\n",
       "      <th>spoken_languages_wo</th>\n",
       "      <th>spoken_languages_xh</th>\n",
       "      <th>spoken_languages_xx</th>\n",
       "      <th>spoken_languages_yi</th>\n",
       "      <th>spoken_languages_za</th>\n",
       "      <th>spoken_languages_zh</th>\n",
       "      <th>spoken_languages_zu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1940.0</td>\n",
       "      <td>2600000</td>\n",
       "      <td>84300000</td>\n",
       "      <td>2.418732</td>\n",
       "      <td>933</td>\n",
       "      <td>6.8</td>\n",
       "      <td>88.0</td>\n",
       "      <td>False</td>\n",
       "      <td>12.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1940.0</td>\n",
       "      <td>1288000</td>\n",
       "      <td>6000000</td>\n",
       "      <td>1.583448</td>\n",
       "      <td>271</td>\n",
       "      <td>7.6</td>\n",
       "      <td>130.0</td>\n",
       "      <td>False</td>\n",
       "      <td>25.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1940.0</td>\n",
       "      <td>2280000</td>\n",
       "      <td>83320000</td>\n",
       "      <td>1.498824</td>\n",
       "      <td>615</td>\n",
       "      <td>7.1</td>\n",
       "      <td>124.0</td>\n",
       "      <td>False</td>\n",
       "      <td>7.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1940.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.113673</td>\n",
       "      <td>160</td>\n",
       "      <td>7.6</td>\n",
       "      <td>112.0</td>\n",
       "      <td>False</td>\n",
       "      <td>28.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1940.0</td>\n",
       "      <td>2000000</td>\n",
       "      <td>11000000</td>\n",
       "      <td>1.005436</td>\n",
       "      <td>563</td>\n",
       "      <td>8.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>False</td>\n",
       "      <td>59.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 514 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   release_date   budget   revenue  popularity  vote_count  vote_average  \\\n",
       "0        1940.0  2600000  84300000    2.418732         933           6.8   \n",
       "1        1940.0  1288000   6000000    1.583448         271           7.6   \n",
       "2        1940.0  2280000  83320000    1.498824         615           7.1   \n",
       "3        1940.0        0         0    1.113673         160           7.6   \n",
       "4        1940.0  2000000  11000000    1.005436         563           8.0   \n",
       "\n",
       "   runtime  adult  n_actors  n_crew         ...           spoken_languages_ur  \\\n",
       "0     88.0  False      12.0    75.0         ...                             0   \n",
       "1    130.0  False      25.0    37.0         ...                             0   \n",
       "2    124.0  False       7.0    24.0         ...                             0   \n",
       "3    112.0  False      28.0    13.0         ...                             0   \n",
       "4    125.0  False      59.0    22.0         ...                             0   \n",
       "\n",
       "   spoken_languages_uz  spoken_languages_vi  spoken_languages_wo  \\\n",
       "0                    0                    0                    0   \n",
       "1                    0                    0                    0   \n",
       "2                    0                    0                    0   \n",
       "3                    0                    0                    0   \n",
       "4                    0                    0                    0   \n",
       "\n",
       "   spoken_languages_xh  spoken_languages_xx  spoken_languages_yi  \\\n",
       "0                    0                    0                    0   \n",
       "1                    0                    0                    0   \n",
       "2                    0                    0                    0   \n",
       "3                    0                    0                    0   \n",
       "4                    0                    0                    0   \n",
       "\n",
       "   spoken_languages_za  spoken_languages_zh  spoken_languages_zu  \n",
       "0                    0                    0                    0  \n",
       "1                    0                    0                    0  \n",
       "2                    0                    0                    0  \n",
       "3                    0                    0                    0  \n",
       "4                    0                    0                    0  \n",
       "\n",
       "[5 rows x 514 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#convert release date string to numeric year\n",
    "rd = features['release_date'].str[:4]\n",
    "rd = pd.to_numeric(rd)\n",
    "\n",
    "features['release_date'] = rd\n",
    "features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a decent number of movies that are missing data for some of the features.  Since we can't fit our models with NaN values present, we can choose to either remove these movies, or impute values for the missing features.  Let's see how many movies we lose by dropping observations with any missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11578"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count missing data to see how many movies we lose by dropping NAs:\n",
    "features.shape[0] - features.dropna().shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we'll lose almost 12K movies by dropping those with any missing values.  Given the large size of our datset, this doesn't seem unmanageable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#make a df with no important features missing\n",
    "feat2 = pd.concat([features, labels], axis=1)\n",
    "feat2 = feat2.dropna()\n",
    "labels2 = feat2.ix[:,514:521]\n",
    "\n",
    "#drop adult since it is always false\n",
    "del feat2['adult']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need to worry about features that have erroneous or nonsensical values, e.g. a budget of $0.00.  These erroneous values could have a negative influence on the model, if they're not dealt with.  So we'll create a new dataset with erroneous values replaced by the mean, with which we'll compare the non-altered dataset later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#make a second df with imputed mean values for nonsensical data in quantitative variables\n",
    "feat3 = feat2.iloc[:,0:9].values\n",
    "feat3 = feat3.astype('float')\n",
    "feat3[feat3 == 0] = np.nan\n",
    "imp = Imputer(missing_values='NaN', strategy='mean', axis=0)\n",
    "feat3 = imp.fit_transform(feat3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>release_date</th>\n",
       "      <th>budget</th>\n",
       "      <th>revenue</th>\n",
       "      <th>popularity</th>\n",
       "      <th>vote_count</th>\n",
       "      <th>vote_average</th>\n",
       "      <th>runtime</th>\n",
       "      <th>n_actors</th>\n",
       "      <th>n_crew</th>\n",
       "      <th>original_language_ab</th>\n",
       "      <th>...</th>\n",
       "      <th>spoken_languages_za</th>\n",
       "      <th>spoken_languages_zh</th>\n",
       "      <th>spoken_languages_zu</th>\n",
       "      <th>Action</th>\n",
       "      <th>Drama</th>\n",
       "      <th>Comedy</th>\n",
       "      <th>Family</th>\n",
       "      <th>Romance</th>\n",
       "      <th>Documentary</th>\n",
       "      <th>Horror</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1940.0</td>\n",
       "      <td>2.600000e+06</td>\n",
       "      <td>8.430000e+07</td>\n",
       "      <td>2.418732</td>\n",
       "      <td>933.0</td>\n",
       "      <td>6.8</td>\n",
       "      <td>88.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1940.0</td>\n",
       "      <td>1.288000e+06</td>\n",
       "      <td>6.000000e+06</td>\n",
       "      <td>1.583448</td>\n",
       "      <td>271.0</td>\n",
       "      <td>7.6</td>\n",
       "      <td>130.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1940.0</td>\n",
       "      <td>2.280000e+06</td>\n",
       "      <td>8.332000e+07</td>\n",
       "      <td>1.498824</td>\n",
       "      <td>615.0</td>\n",
       "      <td>7.1</td>\n",
       "      <td>124.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1940.0</td>\n",
       "      <td>1.523739e+07</td>\n",
       "      <td>6.234904e+07</td>\n",
       "      <td>1.113673</td>\n",
       "      <td>160.0</td>\n",
       "      <td>7.6</td>\n",
       "      <td>112.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1940.0</td>\n",
       "      <td>2.000000e+06</td>\n",
       "      <td>1.100000e+07</td>\n",
       "      <td>1.005436</td>\n",
       "      <td>563.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 519 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   release_date        budget       revenue  popularity  vote_count  \\\n",
       "0        1940.0  2.600000e+06  8.430000e+07    2.418732       933.0   \n",
       "1        1940.0  1.288000e+06  6.000000e+06    1.583448       271.0   \n",
       "2        1940.0  2.280000e+06  8.332000e+07    1.498824       615.0   \n",
       "3        1940.0  1.523739e+07  6.234904e+07    1.113673       160.0   \n",
       "4        1940.0  2.000000e+06  1.100000e+07    1.005436       563.0   \n",
       "\n",
       "   vote_average  runtime  n_actors  n_crew  original_language_ab   ...    \\\n",
       "0           6.8     88.0      12.0    75.0                   0.0   ...     \n",
       "1           7.6    130.0      25.0    37.0                   0.0   ...     \n",
       "2           7.1    124.0       7.0    24.0                   0.0   ...     \n",
       "3           7.6    112.0      28.0    13.0                   0.0   ...     \n",
       "4           8.0    125.0      59.0    22.0                   0.0   ...     \n",
       "\n",
       "   spoken_languages_za  spoken_languages_zh  spoken_languages_zu  Action  \\\n",
       "0                  0.0                  0.0                  0.0     0.0   \n",
       "1                  0.0                  0.0                  0.0     1.0   \n",
       "2                  0.0                  0.0                  0.0     1.0   \n",
       "3                  0.0                  0.0                  0.0     0.0   \n",
       "4                  0.0                  0.0                  0.0     0.0   \n",
       "\n",
       "   Drama  Comedy  Family  Romance  Documentary  Horror  \n",
       "0    0.0     0.0     1.0      0.0          0.0     0.0  \n",
       "1    1.0     0.0     0.0      1.0          0.0     0.0  \n",
       "2    1.0     0.0     1.0      0.0          0.0     0.0  \n",
       "3    0.0     1.0     0.0      1.0          0.0     0.0  \n",
       "4    0.0     1.0     0.0      0.0          0.0     0.0  \n",
       "\n",
       "[5 rows x 519 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat3 = pd.DataFrame(feat3, columns = list(feat2)[0:9])\n",
    "feat3 = pd.concat([feat3, feat2.iloc[:,10:520]], axis=1).dropna()\n",
    "feat3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Pop labels off of imputed dataset\n",
    "labels3 = feat3.ix[:,512:519]\n",
    "feat3 = feat3.drop(feat3.columns[[512, 513, 514, 515, 516, 517, 518]], axis=1)\n",
    "feat2 = feat2.drop(feat2.columns[[513, 514, 515, 516, 517, 518, 519]], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model fitting and comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've cleaned up our data sufficiently, it's finally time to begin model fitting and comparison.  The first step is to split the full dataset into training and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#split our data into training and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(feat2, labels2, test_size=0.33, random_state=42)\n",
    "\n",
    "# ----------------------------\n",
    "# Standardize features\n",
    "scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "# Call: scaler.transform(X_train) to scale\n",
    "# ----------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General strategy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We framed our genre prediction problem as a multi-label task, where a given movie may have >=1 genre labels.  Rather than throwing out movies with >1 genre, or arbitrarily choosing to keep a single genre for each movie, we chose this framework because we believe this approach retains an important aspect of movie genres - that boundaries are often not clear - at the cost of making the classification task more difficult.\n",
    "\n",
    "**Classification scheme:**\n",
    "We first chose to tackle the multi-label task by using a one-vs.-rest classification approach, essentially modeling each genre as the output of a single classifier, since it requires only fitting one classifier per genre.  It's not the most powerful approach, but it more efficient than other classification schemes and is expected to give decent first-pass results.\n",
    "\n",
    "**Model selection:**\n",
    "We wound up fitting three different models to the data - Naive Bayes (NB), Logistic regression (LR), and Random Forests Classifier (RFC) - fitting the LR and RFC with, and without, PCA.\n",
    "\n",
    "**Class imbalance**\n",
    "As we showed in previous milestones, the genres are not all equally common, therefore we have to contend with significant class imbalance.   This could be dealt with in a number of ways, but the way we chose to deal with it is to \"balance\" the groups by adjusting the weights to be inversely proportional to the class frequencies for the LR and and RFC, and setting the priors in NB to the observed frequencies.\n",
    "\n",
    "**Performance Evaluation:**\n",
    "To evaluate performance, we chose to Hamming loss.  We chose Hamming loss, as opposed to other measures, because it gives the label-by-label accuracy for our multi-label classification, and not an \"all or nothing\" accuracy indicating whether we got the exact combination of genres right for a particular movie. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We decided to begin our modeling efforts with a simple Naive Bayes classifier.  The Naive Bayes classifier should be simple to implement and quick to fit this large dataset, so it's a good place to start."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneVsRestClassifier(estimator=GaussianNB(priors=None), n_jobs=-1)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# Do multi-label NB\n",
    "nb_mdl = OneVsRestClassifier(GaussianNB(), n_jobs=-1)\n",
    "nb_mdl.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.310183745244874"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test uncalibrated NB performance\n",
    "nb_pred = nb_mdl.predict(X_test)\n",
    "hamming_loss(y_test, nb_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the NB model appears to do a decent job right out of the box, with a Hamming loss of 0.31.  This means that roughly 69% of our genre labels are predicted correctly for the test set.  Since each genre assignment is a 50/50 choice, this would seem to be a large improvement over a random classifier.  \n",
    "\n",
    "We thought perhaps performance could be improved by tuning the NB model.  There isn't really a good way to 'tune' an NB classifier, but we can calibrate the class probabilities and look at how varying the class threshold affects our loss on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minumum Hamming loss: 0.212766466493\n",
      "Loss when zero: 0.214970572051\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x110aaf190>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "nb_sigmoid = CalibratedClassifierCV(GaussianNB(), method='sigmoid')\n",
    "nb_mdl = OneVsRestClassifier(nb_sigmoid, n_jobs=-1)\n",
    "nb_mdl.fit(X_train, y_train)\n",
    "\n",
    "nb_cal_proba = nb_mdl.predict_proba(X_test)\n",
    "\n",
    "\n",
    "loss = []\n",
    "# Choose optimal threshold by manual ROC\n",
    "for thresh in np.linspace(0.01, 0.99, 99):\n",
    "    \n",
    "    pred = np.array(nb_cal_proba > thresh).astype(int)\n",
    "    loss.append(hamming_loss(y_test, pred))\n",
    "\n",
    "    \n",
    "plt.plot(np.linspace(0.01, 0.99, 99), loss)\n",
    "plt.xlabel('threshold'); plt.ylabel('Hamming Loss')\n",
    "\n",
    "print 'Minumum Hamming loss: {loss}'.format(loss=min(loss))\n",
    "print 'Loss when zero: {loss}'.format(loss=hamming_loss(y_test, np.zeros(np.shape(y_test))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Surprisingly, it seems like the NB classifier does best (Hamming loss = 0.213) at the higest thresholds - when it predicts everything as 0, i.e. no genre assigned.  In fact, it turns out that the best performance achievable here is what we would achieve by assigning no genre to any movie - the \"all null\" model (Hamming loss = 0.215).  This is clearly not the desired effect, since prediction of no genre is completely unhelpful.  We could try to impose a constraint on the model that at least one genre is always chosen, e.g. applying a softmax transformation, but this assumes labels are mutually exclusive, so it can't handle multi-label scenarios like this one.  To circumvent these issues, we decided to try something a bit different, and turned to logistic regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we implement a logistic regression model, using stochastic gradient descent to efficiently fit the large dataset.  As above, we fit our model on the full training dataset, using a one-vs.-rest scheme, and report the Hamming loss performance metric.  The model was previously tuned using the code in the Appendix, and C=100 was identified as the optimal regularization parameter value.  We use that value here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneVsRestClassifier(estimator=LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
       "          solver='sag', tol=0.0001, verbose=0, warm_start=False),\n",
       "          n_jobs=-1)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Now do LR - we'll use the SGD solver since the dataset is so large\n",
    "lr_mdl = OneVsRestClassifier(LogisticRegression(class_weight='balanced', C=100, solver='sag'), n_jobs=-1)\n",
    "lr_mdl.fit(scaler.transform(X_train), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.35005203722755224"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test LR performance\n",
    "lr_pred = lr_mdl.predict(scaler.transform(X_test))\n",
    "hamming_loss(y_test, lr_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1, 0, 0, 0, 0],\n",
       "       [0, 0, 1, 0, 1, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 1, 0],\n",
       "       [1, 0, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 1, 0, 1, 1],\n",
       "       [1, 0, 0, 1, 0, 1, 0],\n",
       "       [0, 0, 0, 1, 0, 1, 0],\n",
       "       [0, 0, 1, 0, 0, 0, 0],\n",
       "       [1, 0, 1, 0, 1, 0, 0],\n",
       "       [1, 0, 1, 0, 1, 0, 1]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's look at the first handful of genre predictions\n",
    "lr_pred[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that our untuned LR does worse than the NB model and how we would do by simply predicting all zeros for the genres (Hamming loss of 0.350 vs. 0.215), but at least it does assign movies at least one genre.  Presumably, performance would improve with some finer tuning of the regularization strength, but it seems doubtful that we will get too far with this model and this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA\n",
    "\n",
    "To see whether we can improve performance by reducing the dimensionality of the feature space we implemented PCA and kept the minimum number of PCs required to explain 90% of the total variance.  This will hopefully make the model fitting faster, and result in higher quality predictions. We will apply PCA to the logistic regression model above to see whether performance can be improved, and to the RFC below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCA(copy=True, iterated_power='auto', n_components=400, random_state=None,\n",
       "  svd_solver='auto', tol=0.0, whiten=False)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# implementation of LR using PCA to see if this results in better prediction\n",
    "# start with 400 PCs, will only take the ones that explain ~90% of variance\n",
    "pca = PCA(n_components=400)\n",
    "pca.fit(scaler.transform(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "327\n",
      "0.900468664604\n"
     ]
    }
   ],
   "source": [
    "# show the number of PCs that explain at least 90% of the variance\n",
    "var90pcs = len(pca.explained_variance_ratio_[np.cumsum(pca.explained_variance_ratio_)<.9])\n",
    "print var90pcs\n",
    "print np.cumsum(pca.explained_variance_ratio_)[var90pcs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that 90% of the variance is explained by the first 327 PCs, so we will fit our LR using the first 327 PCs and compare the results to the model using the entire dataset above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(96981, 400)\n",
      "(47768, 400)\n"
     ]
    }
   ],
   "source": [
    "# reduce data using PCA\n",
    "X_train_reduced = pca.transform(scaler.transform(X_train))\n",
    "print X_train_reduced.shape\n",
    "X_test_reduced = pca.transform(scaler.transform(X_test))\n",
    "print X_test_reduced.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneVsRestClassifier(estimator=LogisticRegression(C=100, class_weight='balanced', dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
       "          solver='sag', tol=0.0001, verbose=0, warm_start=False),\n",
       "          n_jobs=-1)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now the same LR as above but with 327 principal components\n",
    "lr_mdl_pca = OneVsRestClassifier(LogisticRegression(class_weight='balanced', C=100, solver='sag'), n_jobs=-1)\n",
    "lr_mdl_pca.fit(X_train_reduced[:,0:var90pcs], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.35687070842404955"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test LR performance\n",
    "lr_pred_pca = lr_mdl_pca.predict(X_test_reduced[:,0:var90pcs])\n",
    "hamming_loss(y_test, lr_pred_pca)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the Hamming loss is pretty similar to that achieved using the full data set, only slightly worse.  This indicates that the features aren't very compressible, i.e. information is distributed widely across features. It is possible that we will will see gains by implementing a more flexible classifier, so we decided to fit an RFC, and compare results with those above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As with the LR, we pre-tuned our RFC using the code in the Appendix and apply those values here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.16755688207287606"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#run a tuned RFC on full data set and calculate Hamming loss\n",
    "# **tuning parameters chosen previously using code in the Appendix\n",
    "rfc_mdl = RFC(n_estimators=120, max_depth=60, class_weight ='balanced', n_jobs=-1).fit(X_train,y_train)\n",
    "rf_pred = rfc_mdl.predict(X_test)\n",
    "hamming_loss(y_test, rf_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that we achieve a significantly better Hamming score with RFC (0.17) than with NB or LR.  This means that roughly 83% of our genre labels are predicted correctly for the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.28720063640931165"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calculate the overall accuracy of our predictions\n",
    "rfc_mdl.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also compared the Hamming score metric with a more traditional overall accuracy metric.  From the sklearn documentation: \"In multi-label classification, this is the subset accuracy which is a harsh metric since you require for each sample that each label set be correctly predicted.\" While interesting to compare to the Hamming loss, this gives us a much coarser picture of how our model is performing at assigning genres. 29% of our films' genres are predicted exactly as we assigned them, but 83% of our predicted genres are correct. Since a random classifier would need to assign seven binary genres correctly to get one movie correct on this harsh metric, each movie would have a (.5)^7 or roughly 0.8% chance of being assigned correctly. \n",
    "\n",
    "Next, we apply PCA and see whether dimensionality reduction improves RFC performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.17694750819436803"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#run a tuned RFC on our data that has been reduced using PCA and calculate Hamming loss\n",
    "rfc_mdl_pca = RFC(n_estimators=120, max_depth=60, class_weight = 'balanced').fit(X_train_reduced[:,0:var90pcs],y_train)\n",
    "pred_pca = rfc_mdl_pca.predict(np.array(X_test_reduced[:,0:var90pcs]))\n",
    "hamming_loss(y_test, pred_pca)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "About 82% of the genres are predicted correctly using PCA with 327 PCs. This is pretty comparable to the RFC above that uses the full dimension dataset. Perhaps the slight loss in accuracy is offset by the reduction in time it takes to fit the random forest, although this is a subjective judgment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Performance by genre"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's important to consider how the different models are making their mistakes, so we decided to break down the prediction accuracy by genre for the LR and RFC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#visualize by-genre accuracy of predictions\n",
    "def plot_acc_by_genre(pred, y_test, clf_str=''):\n",
    "    \n",
    "    preds = pd.DataFrame(pred)\n",
    "    acc = []\n",
    "\n",
    "    for i in range(7):\n",
    "        a = np.array(y_test[[i]])\n",
    "        b = np.array(preds[[i]])\n",
    "        acc.append(np.count_nonzero(a==b) / preds.shape[0] * 100)\n",
    "\n",
    "    plt.figure(figsize=(10,5))\n",
    "    index = [0,1,2,3,4,5,6]\n",
    "    plt.bar(index,acc,align=\"center\")\n",
    "    plt.xticks(index, ('Action', 'Drama', 'Comedy', 'Family', 'Romance', 'Documentary', 'Horror'))\n",
    "    plt.ylim([0,100])\n",
    "    plt.grid(axis='y')\n",
    "    plt.title(clf_str + ' Accuracy by Genre')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmcAAAE/CAYAAAADh2QWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJEnqEcOZJElSj/x/4a4DnTmivS4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x13a304210>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_acc_by_genre(lr_pred, y_test, 'Logistic Regression')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmcAAAE/CAYAAAADh2QWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nI4YzSZKkHvn/Olr0JSNEO50AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1191c0090>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_acc_by_genre(rf_pred, y_test, 'Random Forest')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the LR, accuracy is pretty similar across action, drama, comedy, and horror, while family and documentary genres are predicted with slightly higher fidelity.  \n",
    "\n",
    "For RFC, we correctly identify 4 out of our 7 combined genres almost 90% of the time, while action and comedy are accurately labeled roughly 75% of the time. Drama is the only genre with a lower than 70% accuracy rating, indicating that we may need to rethink which of our original genres we are flagging for inclusion in this category. It is also a genre that appears with a wide variety of other film types, making its discrimination more difficult.\n",
    "\n",
    "Overall, the LR and RFC don't look drastically different, beyond the overall higher performance of RFC."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the importance of categorical features and effects of missing data in RF model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We next wanted to evaluate the contributions of different categorical variables we chose to include, as well as the effects of imputing data.  We first look at performance of our tuned RFC on the imputed dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.20405906794877168"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#split our imputed data df into training and testing\n",
    "X_train3, X_test3, y_train3, y_test3 = train_test_split(feat3, labels3, test_size=0.33, random_state=42)\n",
    "\n",
    "#run a RFC on our data with imputed data\n",
    "imputedmdl = RFC(n_estimators=120, max_depth=60, class_weight = 'balanced', n_jobs=-1).fit(X_train3,y_train3)\n",
    "pred3 = imputedmdl.predict(X_test3)\n",
    "hamming_loss(y_test3, pred3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This means that roughly 80% of our genre labels are predicted correctly for the test set when using the dataset with imputed data. As this performance is worse than leaving erroneous value in place, we will continue to test other methods of handling missing / nonsensical data.\n",
    "\n",
    "Next, we wondered whether including information about languages and production location significantly improved predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#build several dfs with different predictors\n",
    "a = X_train.ix[:,0:9] #just the basics\n",
    "b = X_train.ix[:,0:132] #include original language\n",
    "c = X_train.ix[:,0:365] #include production countries\n",
    "d = X_train #include spoken language\n",
    "\n",
    "e = X_test.ix[:,0:9] #just the basics\n",
    "f = X_test.ix[:,0:132] #include original language\n",
    "g = X_test.ix[:,0:365] #include production countries\n",
    "h = X_test #include spoken language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.17707311529535613, 0.1715434122066177, 0.16805931047682848, 0.16764959207598631]\n"
     ]
    }
   ],
   "source": [
    "#run models on each df\n",
    "dfs_train = [a,b,c,d]\n",
    "dfs_test = [e,f,g,h]\n",
    "loss = []\n",
    "\n",
    "for i in range(4):\n",
    "    mdl = RFC(n_estimators=120, max_depth=60, class_weight = 'balanced', n_jobs=-1).fit(dfs_train[i],y_train)\n",
    "    pred = mdl.predict(dfs_test[i])\n",
    "    loss.append(hamming_loss(y_test, pred))\n",
    "    \n",
    "print loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAnEAAAE/CAYAAAApN5W5AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x141970e10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "index = [0,1,2,3]\n",
    "plt.bar(index,loss,align=\"center\")\n",
    "plt.xticks(index, ('Basics', '+ Original language', '+ Production Countries', '+ Spoken Language'))\n",
    "plt.ylim([0,0.2])\n",
    "plt.grid(axis='y')\n",
    "plt.title('Random Forest with Different Attributes of Films')\n",
    "plt.ylabel('Hamming loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, ading all our language and country predictors as indicator variables leads to a 1% improvement in classifier performance.  This is not a huge gain, but perhaps worth the added overhead.\n",
    "\n",
    "Next, we wondered whether the different \"basic\" features had roughly similar importance for RFC predictions.  We evaluated this by looking at the RFC importance scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAEICAYAAAC9E5gJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n7/IROd0J8AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1418f2b50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "importances = rfc_mdl.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in rfc_mdl.estimators_],\n",
    "             axis=0)\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# Plot the feature importances of the forest\n",
    "plt.figure()\n",
    "plt.title(\"Feature importances\")\n",
    "plt.bar(range(X_train.shape[1]), importances[indices],\n",
    "       color=\"r\", yerr=std[indices], align=\"center\")\n",
    "plt.xticks(range(X_train.shape[1]), indices)\n",
    "plt.xlim([-1, 15])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see from the above visualization, seven features proved the most important in determining the movie genres for our Random Forest Classifier. The top nine contributors came from our \"basic\" core of quanitiative data scraped from TMDb and are, in order: running time, popularity, release year, # of actors, # of crew, vote average, and vote count. Budget and revenue come last among these variables and suffer from having a large amount of missing data compared to our other features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature ranking:\n",
      "1. feature 6 (0.136471)\n",
      "2. feature 3 (0.131113)\n",
      "3. feature 0 (0.117326)\n",
      "4. feature 7 (0.113605)\n",
      "5. feature 8 (0.084507)\n",
      "6. feature 5 (0.082935)\n",
      "7. feature 4 (0.069611)\n",
      "8. feature 1 (0.024706)\n",
      "9. feature 2 (0.014729)\n",
      "10. feature 394 (0.012339)\n",
      "11. feature 345 (0.011786)\n",
      "12. feature 235 (0.008720)\n",
      "13. feature 35 (0.008469)\n",
      "14. feature 423 (0.007209)\n",
      "15. feature 203 (0.006606)\n",
      "16. feature 390 (0.006119)\n",
      "17. feature 166 (0.006049)\n",
      "18. feature 403 (0.005994)\n",
      "19. feature 396 (0.005037)\n",
      "20. feature 201 (0.004618)\n",
      "21. feature 62 (0.004548)\n",
      "22. feature 227 (0.004233)\n",
      "23. feature 183 (0.004148)\n",
      "24. feature 421 (0.003273)\n",
      "25. feature 470 (0.003135)\n",
      "26. feature 232 (0.002911)\n",
      "27. feature 145 (0.002812)\n",
      "28. feature 194 (0.002714)\n",
      "29. feature 508 (0.002537)\n",
      "30. feature 43 (0.002503)\n",
      "31. feature 31 (0.002501)\n",
      "32. feature 489 (0.002429)\n",
      "33. feature 219 (0.002287)\n",
      "34. feature 383 (0.002267)\n",
      "35. feature 511 (0.002264)\n",
      "36. feature 307 (0.002250)\n",
      "37. feature 413 (0.002086)\n",
      "38. feature 243 (0.002068)\n",
      "39. feature 467 (0.002020)\n",
      "40. feature 386 (0.001939)\n",
      "41. feature 431 (0.001909)\n",
      "42. feature 416 (0.001831)\n",
      "43. feature 37 (0.001782)\n",
      "44. feature 465 (0.001688)\n",
      "45. feature 295 (0.001573)\n",
      "46. feature 151 (0.001550)\n",
      "47. feature 60 (0.001538)\n",
      "48. feature 114 (0.001535)\n",
      "49. feature 277 (0.001510)\n",
      "50. feature 182 (0.001502)\n",
      "51. feature 495 (0.001491)\n",
      "52. feature 312 (0.001473)\n",
      "53. feature 185 (0.001469)\n",
      "54. feature 490 (0.001456)\n",
      "55. feature 389 (0.001369)\n",
      "56. feature 487 (0.001335)\n",
      "57. feature 69 (0.001302)\n",
      "58. feature 99 (0.001289)\n",
      "59. feature 175 (0.001263)\n",
      "60. feature 492 (0.001257)\n",
      "61. feature 456 (0.001203)\n",
      "62. feature 285 (0.001193)\n",
      "63. feature 28 (0.001116)\n",
      "64. feature 25 (0.001041)\n",
      "65. feature 170 (0.001034)\n",
      "66. feature 30 (0.001012)\n",
      "67. feature 160 (0.001007)\n",
      "68. feature 340 (0.000972)\n",
      "69. feature 130 (0.000936)\n",
      "70. feature 330 (0.000910)\n",
      "71. feature 144 (0.000881)\n",
      "72. feature 225 (0.000862)\n",
      "73. feature 305 (0.000851)\n",
      "74. feature 446 (0.000845)\n",
      "75. feature 369 (0.000836)\n",
      "76. feature 297 (0.000822)\n",
      "77. feature 90 (0.000808)\n",
      "78. feature 289 (0.000795)\n",
      "79. feature 450 (0.000783)\n",
      "80. feature 498 (0.000781)\n",
      "81. feature 96 (0.000769)\n",
      "82. feature 142 (0.000765)\n",
      "83. feature 52 (0.000764)\n",
      "84. feature 393 (0.000762)\n",
      "85. feature 362 (0.000735)\n",
      "86. feature 337 (0.000726)\n",
      "87. feature 112 (0.000723)\n",
      "88. feature 94 (0.000706)\n",
      "89. feature 286 (0.000700)\n",
      "90. feature 117 (0.000684)\n",
      "91. feature 196 (0.000659)\n",
      "92. feature 115 (0.000658)\n",
      "93. feature 214 (0.000643)\n",
      "94. feature 278 (0.000633)\n",
      "95. feature 223 (0.000632)\n",
      "96. feature 412 (0.000624)\n",
      "97. feature 430 (0.000623)\n",
      "98. feature 401 (0.000596)\n",
      "99. feature 458 (0.000594)\n",
      "100. feature 119 (0.000581)\n",
      "101. feature 484 (0.000555)\n",
      "102. feature 418 (0.000544)\n",
      "103. feature 226 (0.000533)\n",
      "104. feature 91 (0.000531)\n",
      "105. feature 153 (0.000523)\n",
      "106. feature 342 (0.000487)\n",
      "107. feature 298 (0.000480)\n",
      "108. feature 173 (0.000456)\n",
      "109. feature 224 (0.000442)\n",
      "110. feature 469 (0.000434)\n",
      "111. feature 300 (0.000413)\n",
      "112. feature 81 (0.000413)\n",
      "113. feature 221 (0.000407)\n",
      "114. feature 105 (0.000398)\n",
      "115. feature 120 (0.000392)\n",
      "116. feature 231 (0.000375)\n",
      "117. feature 56 (0.000369)\n",
      "118. feature 479 (0.000361)\n",
      "119. feature 414 (0.000331)\n",
      "120. feature 34 (0.000330)\n",
      "121. feature 316 (0.000311)\n",
      "122. feature 191 (0.000309)\n",
      "123. feature 313 (0.000287)\n",
      "124. feature 436 (0.000285)\n",
      "125. feature 420 (0.000277)\n",
      "126. feature 399 (0.000277)\n",
      "127. feature 121 (0.000277)\n",
      "128. feature 306 (0.000272)\n",
      "129. feature 255 (0.000255)\n",
      "130. feature 462 (0.000248)\n",
      "131. feature 190 (0.000246)\n",
      "132. feature 464 (0.000241)\n",
      "133. feature 41 (0.000240)\n",
      "134. feature 54 (0.000238)\n",
      "135. feature 314 (0.000226)\n",
      "136. feature 179 (0.000226)\n",
      "137. feature 478 (0.000223)\n",
      "138. feature 374 (0.000222)\n",
      "139. feature 164 (0.000217)\n",
      "140. feature 502 (0.000205)\n",
      "141. feature 366 (0.000204)\n",
      "142. feature 397 (0.000203)\n",
      "143. feature 110 (0.000203)\n",
      "144. feature 505 (0.000197)\n",
      "145. feature 381 (0.000196)\n",
      "146. feature 350 (0.000189)\n",
      "147. feature 292 (0.000189)\n",
      "148. feature 53 (0.000188)\n",
      "149. feature 133 (0.000187)\n",
      "150. feature 331 (0.000182)\n",
      "151. feature 176 (0.000179)\n",
      "152. feature 23 (0.000168)\n",
      "153. feature 68 (0.000165)\n",
      "154. feature 230 (0.000159)\n",
      "155. feature 13 (0.000157)\n",
      "156. feature 361 (0.000157)\n",
      "157. feature 104 (0.000151)\n",
      "158. feature 417 (0.000149)\n",
      "159. feature 254 (0.000148)\n",
      "160. feature 377 (0.000145)\n",
      "161. feature 98 (0.000144)\n",
      "162. feature 51 (0.000141)\n",
      "163. feature 483 (0.000137)\n",
      "164. feature 109 (0.000131)\n",
      "165. feature 178 (0.000128)\n",
      "166. feature 137 (0.000127)\n",
      "167. feature 205 (0.000124)\n",
      "168. feature 187 (0.000124)\n",
      "169. feature 503 (0.000114)\n",
      "170. feature 509 (0.000114)\n",
      "171. feature 476 (0.000112)\n",
      "172. feature 40 (0.000112)\n",
      "173. feature 10 (0.000109)\n",
      "174. feature 124 (0.000106)\n",
      "175. feature 85 (0.000104)\n",
      "176. feature 440 (0.000102)\n",
      "177. feature 264 (0.000096)\n",
      "178. feature 425 (0.000096)\n",
      "179. feature 388 (0.000090)\n",
      "180. feature 38 (0.000089)\n",
      "181. feature 283 (0.000087)\n",
      "182. feature 75 (0.000087)\n",
      "183. feature 256 (0.000083)\n",
      "184. feature 353 (0.000083)\n",
      "185. feature 93 (0.000082)\n",
      "186. feature 127 (0.000081)\n",
      "187. feature 427 (0.000076)\n",
      "188. feature 238 (0.000074)\n",
      "189. feature 512 (0.000071)\n",
      "190. feature 447 (0.000068)\n",
      "191. feature 380 (0.000068)\n",
      "192. feature 406 (0.000068)\n",
      "193. feature 59 (0.000067)\n",
      "194. feature 429 (0.000065)\n",
      "195. feature 398 (0.000065)\n",
      "196. feature 323 (0.000065)\n",
      "197. feature 441 (0.000064)\n",
      "198. feature 347 (0.000063)\n",
      "199. feature 455 (0.000062)\n",
      "200. feature 220 (0.000062)\n",
      "201. feature 504 (0.000061)\n",
      "202. feature 259 (0.000060)\n",
      "203. feature 449 (0.000059)\n",
      "204. feature 18 (0.000056)\n",
      "205. feature 148 (0.000056)\n",
      "206. feature 445 (0.000055)\n",
      "207. feature 258 (0.000054)\n",
      "208. feature 189 (0.000054)\n",
      "209. feature 246 (0.000054)\n",
      "210. feature 64 (0.000053)\n",
      "211. feature 299 (0.000052)\n",
      "212. feature 444 (0.000051)\n",
      "213. feature 123 (0.000050)\n",
      "214. feature 346 (0.000049)\n",
      "215. feature 409 (0.000048)\n",
      "216. feature 273 (0.000048)\n",
      "217. feature 88 (0.000045)\n",
      "218. feature 20 (0.000044)\n",
      "219. feature 248 (0.000044)\n",
      "220. feature 296 (0.000044)\n",
      "221. feature 356 (0.000042)\n",
      "222. feature 302 (0.000042)\n",
      "223. feature 284 (0.000042)\n",
      "224. feature 135 (0.000041)\n",
      "225. feature 102 (0.000040)\n",
      "226. feature 177 (0.000039)\n",
      "227. feature 76 (0.000039)\n",
      "228. feature 236 (0.000039)\n",
      "229. feature 507 (0.000038)\n",
      "230. feature 405 (0.000037)\n",
      "231. feature 287 (0.000036)\n",
      "232. feature 242 (0.000035)\n",
      "233. feature 270 (0.000035)\n",
      "234. feature 482 (0.000035)\n",
      "235. feature 251 (0.000035)\n",
      "236. feature 159 (0.000034)\n",
      "237. feature 433 (0.000033)\n",
      "238. feature 150 (0.000033)\n",
      "239. feature 488 (0.000032)\n",
      "240. feature 215 (0.000031)\n",
      "241. feature 11 (0.000031)\n",
      "242. feature 22 (0.000030)\n",
      "243. feature 39 (0.000030)\n",
      "244. feature 324 (0.000030)\n",
      "245. feature 80 (0.000029)\n",
      "246. feature 338 (0.000029)\n",
      "247. feature 303 (0.000028)\n",
      "248. feature 207 (0.000027)\n",
      "249. feature 506 (0.000027)\n",
      "250. feature 454 (0.000027)\n",
      "251. feature 165 (0.000026)\n",
      "252. feature 181 (0.000026)\n",
      "253. feature 266 (0.000025)\n",
      "254. feature 250 (0.000025)\n",
      "255. feature 378 (0.000025)\n",
      "256. feature 451 (0.000024)\n",
      "257. feature 47 (0.000024)\n",
      "258. feature 261 (0.000024)\n",
      "259. feature 29 (0.000023)\n",
      "260. feature 247 (0.000023)\n",
      "261. feature 335 (0.000023)\n",
      "262. feature 188 (0.000023)\n",
      "263. feature 291 (0.000022)\n",
      "264. feature 134 (0.000022)\n",
      "265. feature 452 (0.000021)\n",
      "266. feature 122 (0.000020)\n",
      "267. feature 439 (0.000020)\n",
      "268. feature 395 (0.000020)\n",
      "269. feature 408 (0.000020)\n",
      "270. feature 229 (0.000020)\n",
      "271. feature 267 (0.000020)\n",
      "272. feature 434 (0.000020)\n",
      "273. feature 293 (0.000020)\n",
      "274. feature 67 (0.000019)\n",
      "275. feature 172 (0.000019)\n",
      "276. feature 84 (0.000019)\n",
      "277. feature 167 (0.000019)\n",
      "278. feature 138 (0.000018)\n",
      "279. feature 468 (0.000018)\n",
      "280. feature 510 (0.000017)\n",
      "281. feature 372 (0.000017)\n",
      "282. feature 163 (0.000017)\n",
      "283. feature 143 (0.000017)\n",
      "284. feature 357 (0.000017)\n",
      "285. feature 234 (0.000017)\n",
      "286. feature 233 (0.000017)\n",
      "287. feature 319 (0.000017)\n",
      "288. feature 213 (0.000016)\n",
      "289. feature 460 (0.000015)\n",
      "290. feature 363 (0.000015)\n",
      "291. feature 49 (0.000014)\n",
      "292. feature 282 (0.000014)\n",
      "293. feature 195 (0.000013)\n",
      "294. feature 158 (0.000013)\n",
      "295. feature 147 (0.000013)\n",
      "296. feature 382 (0.000013)\n",
      "297. feature 149 (0.000012)\n",
      "298. feature 268 (0.000012)\n",
      "299. feature 341 (0.000012)\n",
      "300. feature 161 (0.000012)\n",
      "301. feature 152 (0.000011)\n",
      "302. feature 407 (0.000011)\n",
      "303. feature 222 (0.000011)\n",
      "304. feature 197 (0.000011)\n",
      "305. feature 419 (0.000011)\n",
      "306. feature 437 (0.000011)\n",
      "307. feature 97 (0.000010)\n",
      "308. feature 252 (0.000010)\n",
      "309. feature 245 (0.000010)\n",
      "310. feature 209 (0.000010)\n",
      "311. feature 325 (0.000010)\n",
      "312. feature 154 (0.000010)\n",
      "313. feature 368 (0.000010)\n",
      "314. feature 237 (0.000010)\n",
      "315. feature 262 (0.000010)\n",
      "316. feature 339 (0.000009)\n",
      "317. feature 280 (0.000009)\n",
      "318. feature 344 (0.000008)\n",
      "319. feature 334 (0.000008)\n",
      "320. feature 257 (0.000008)\n",
      "321. feature 438 (0.000008)\n",
      "322. feature 364 (0.000008)\n",
      "323. feature 415 (0.000008)\n",
      "324. feature 471 (0.000008)\n",
      "325. feature 497 (0.000008)\n",
      "326. feature 354 (0.000007)\n",
      "327. feature 477 (0.000007)\n",
      "328. feature 326 (0.000007)\n",
      "329. feature 174 (0.000007)\n",
      "330. feature 140 (0.000007)\n",
      "331. feature 265 (0.000007)\n",
      "332. feature 422 (0.000007)\n",
      "333. feature 376 (0.000007)\n",
      "334. feature 402 (0.000007)\n",
      "335. feature 146 (0.000007)\n",
      "336. feature 320 (0.000007)\n",
      "337. feature 156 (0.000006)\n",
      "338. feature 239 (0.000006)\n",
      "339. feature 260 (0.000006)\n",
      "340. feature 55 (0.000006)\n",
      "341. feature 392 (0.000006)\n",
      "342. feature 184 (0.000006)\n",
      "343. feature 485 (0.000006)\n",
      "344. feature 141 (0.000006)\n",
      "345. feature 202 (0.000006)\n",
      "346. feature 343 (0.000006)\n",
      "347. feature 103 (0.000006)\n",
      "348. feature 411 (0.000006)\n",
      "349. feature 486 (0.000005)\n",
      "350. feature 244 (0.000005)\n",
      "351. feature 500 (0.000005)\n",
      "352. feature 162 (0.000005)\n",
      "353. feature 200 (0.000005)\n",
      "354. feature 169 (0.000005)\n",
      "355. feature 328 (0.000004)\n",
      "356. feature 168 (0.000004)\n",
      "357. feature 157 (0.000004)\n",
      "358. feature 73 (0.000004)\n",
      "359. feature 424 (0.000004)\n",
      "360. feature 466 (0.000004)\n",
      "361. feature 304 (0.000004)\n",
      "362. feature 349 (0.000004)\n",
      "363. feature 463 (0.000004)\n",
      "364. feature 186 (0.000004)\n",
      "365. feature 42 (0.000004)\n",
      "366. feature 276 (0.000004)\n",
      "367. feature 125 (0.000004)\n",
      "368. feature 443 (0.000004)\n",
      "369. feature 281 (0.000004)\n",
      "370. feature 74 (0.000004)\n",
      "371. feature 327 (0.000003)\n",
      "372. feature 332 (0.000003)\n",
      "373. feature 288 (0.000003)\n",
      "374. feature 171 (0.000003)\n",
      "375. feature 442 (0.000003)\n",
      "376. feature 481 (0.000003)\n",
      "377. feature 384 (0.000003)\n",
      "378. feature 311 (0.000003)\n",
      "379. feature 435 (0.000003)\n",
      "380. feature 387 (0.000003)\n",
      "381. feature 501 (0.000003)\n",
      "382. feature 16 (0.000003)\n",
      "383. feature 86 (0.000003)\n",
      "384. feature 65 (0.000003)\n",
      "385. feature 275 (0.000002)\n",
      "386. feature 50 (0.000002)\n",
      "387. feature 58 (0.000002)\n",
      "388. feature 210 (0.000002)\n",
      "389. feature 308 (0.000002)\n",
      "390. feature 279 (0.000002)\n",
      "391. feature 263 (0.000002)\n",
      "392. feature 474 (0.000002)\n",
      "393. feature 373 (0.000002)\n",
      "394. feature 391 (0.000002)\n",
      "395. feature 271 (0.000002)\n",
      "396. feature 32 (0.000002)\n",
      "397. feature 359 (0.000002)\n",
      "398. feature 139 (0.000002)\n",
      "399. feature 82 (0.000002)\n",
      "400. feature 45 (0.000002)\n",
      "401. feature 301 (0.000002)\n",
      "402. feature 155 (0.000002)\n",
      "403. feature 128 (0.000002)\n",
      "404. feature 321 (0.000002)\n",
      "405. feature 428 (0.000002)\n",
      "406. feature 385 (0.000002)\n",
      "407. feature 211 (0.000002)\n",
      "408. feature 78 (0.000002)\n",
      "409. feature 217 (0.000002)\n",
      "410. feature 432 (0.000002)\n",
      "411. feature 204 (0.000002)\n",
      "412. feature 480 (0.000002)\n",
      "413. feature 57 (0.000002)\n",
      "414. feature 318 (0.000002)\n",
      "415. feature 70 (0.000002)\n",
      "416. feature 410 (0.000001)\n",
      "417. feature 322 (0.000001)\n",
      "418. feature 269 (0.000001)\n",
      "419. feature 367 (0.000001)\n",
      "420. feature 453 (0.000001)\n",
      "421. feature 116 (0.000001)\n",
      "422. feature 491 (0.000001)\n",
      "423. feature 358 (0.000001)\n",
      "424. feature 496 (0.000001)\n",
      "425. feature 132 (0.000001)\n",
      "426. feature 240 (0.000001)\n",
      "427. feature 19 (0.000001)\n",
      "428. feature 309 (0.000001)\n",
      "429. feature 290 (0.000001)\n",
      "430. feature 370 (0.000001)\n",
      "431. feature 461 (0.000001)\n",
      "432. feature 180 (0.000001)\n",
      "433. feature 315 (0.000001)\n",
      "434. feature 317 (0.000001)\n",
      "435. feature 457 (0.000001)\n",
      "436. feature 253 (0.000001)\n",
      "437. feature 499 (0.000001)\n",
      "438. feature 17 (0.000001)\n",
      "439. feature 360 (0.000001)\n",
      "440. feature 228 (0.000001)\n",
      "441. feature 426 (0.000001)\n",
      "442. feature 111 (0.000001)\n",
      "443. feature 329 (0.000001)\n",
      "444. feature 87 (0.000001)\n",
      "445. feature 71 (0.000001)\n",
      "446. feature 208 (0.000001)\n",
      "447. feature 494 (0.000001)\n",
      "448. feature 107 (0.000001)\n",
      "449. feature 198 (0.000001)\n",
      "450. feature 21 (0.000001)\n",
      "451. feature 333 (0.000001)\n",
      "452. feature 294 (0.000001)\n",
      "453. feature 472 (0.000001)\n",
      "454. feature 216 (0.000001)\n",
      "455. feature 212 (0.000001)\n",
      "456. feature 61 (0.000001)\n",
      "457. feature 473 (0.000001)\n",
      "458. feature 274 (0.000000)\n",
      "459. feature 136 (0.000000)\n",
      "460. feature 404 (0.000000)\n",
      "461. feature 351 (0.000000)\n",
      "462. feature 131 (0.000000)\n",
      "463. feature 66 (0.000000)\n",
      "464. feature 310 (0.000000)\n",
      "465. feature 33 (0.000000)\n",
      "466. feature 206 (0.000000)\n",
      "467. feature 63 (0.000000)\n",
      "468. feature 48 (0.000000)\n",
      "469. feature 459 (0.000000)\n",
      "470. feature 336 (0.000000)\n",
      "471. feature 72 (0.000000)\n",
      "472. feature 108 (0.000000)\n",
      "473. feature 95 (0.000000)\n",
      "474. feature 77 (0.000000)\n",
      "475. feature 15 (0.000000)\n",
      "476. feature 106 (0.000000)\n",
      "477. feature 44 (0.000000)\n",
      "478. feature 118 (0.000000)\n",
      "479. feature 126 (0.000000)\n",
      "480. feature 89 (0.000000)\n",
      "481. feature 355 (0.000000)\n",
      "482. feature 129 (0.000000)\n",
      "483. feature 113 (0.000000)\n",
      "484. feature 400 (0.000000)\n",
      "485. feature 218 (0.000000)\n",
      "486. feature 14 (0.000000)\n",
      "487. feature 352 (0.000000)\n",
      "488. feature 12 (0.000000)\n",
      "489. feature 375 (0.000000)\n",
      "490. feature 9 (0.000000)\n",
      "491. feature 348 (0.000000)\n",
      "492. feature 26 (0.000000)\n",
      "493. feature 272 (0.000000)\n",
      "494. feature 249 (0.000000)\n",
      "495. feature 83 (0.000000)\n",
      "496. feature 379 (0.000000)\n",
      "497. feature 46 (0.000000)\n",
      "498. feature 92 (0.000000)\n",
      "499. feature 371 (0.000000)\n",
      "500. feature 241 (0.000000)\n",
      "501. feature 199 (0.000000)\n",
      "502. feature 475 (0.000000)\n",
      "503. feature 448 (0.000000)\n",
      "504. feature 493 (0.000000)\n",
      "505. feature 36 (0.000000)\n",
      "506. feature 79 (0.000000)\n",
      "507. feature 100 (0.000000)\n",
      "508. feature 101 (0.000000)\n",
      "509. feature 192 (0.000000)\n",
      "510. feature 27 (0.000000)\n",
      "511. feature 365 (0.000000)\n",
      "512. feature 24 (0.000000)\n",
      "513. feature 193 (0.000000)\n"
     ]
    }
   ],
   "source": [
    "# Print the full feature ranking\n",
    "print(\"Feature ranking:\")\n",
    "\n",
    "for f in range(X_train.shape[1]):\n",
    "    print(\"%d. feature %d (%f)\" % (f + 1, indices[f], importances[indices[f]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Appendix:  model tuning code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Tuning for LR model\n",
    "loss = []\n",
    "\n",
    "for tuning_param in np.array([0.001, 0.01, 0.05, 0.1, 0.2, 0.5, 1.0, 2.0, 5.0, 10.0 100]):\n",
    "    \n",
    "    lr_mdl = OneVsRestClassifier(LogisticRegression(class_weight ='balanced', C=tuning_param, solver='sag'), n_jobs=-1)\n",
    "    lr_mdl.fit(scaler.transform(X_train), y_train)\n",
    "\n",
    "    # Test LR performance\n",
    "    lr_pred = lr_mdl.predict(scaler.transform(X_test))\n",
    "    loss.append(hamming_loss(y_test, lr_pred))\n",
    "    \n",
    "plt.plot([0.001, 0.01, 0.05, 0.1, 0.2, 0.5, 1.0, 2.0, 5.0, 10.0, 100], loss)\n",
    "plt.xlabel('regularization tuning parameter'); plt.ylabel('Hamming loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Tuning for random forest model\n",
    "\n",
    "n_folds = 5\n",
    "kf = KFold(n_splits=n_folds)\n",
    "\n",
    "# Parameters for tuning a random forest model\n",
    "n_trees = np.arange(10, 100, 20)  # Trees and depth are explored on an exponentially growing space,\n",
    "depths = np.arange(2, 10)   # since it is assumed that trees and depth will add accuracy in a decaying fashion.\n",
    "\n",
    "# To keep track of the best model\n",
    "best_score = 1\n",
    "\n",
    "# Run grid search for model with 5-fold cross validation\n",
    "print '5-fold cross validation:'\n",
    "    \n",
    "for trees in n_trees:\n",
    "    for depth in depths:\n",
    "        loss = []\n",
    "        for ktrain, ktest in kf.split(feat2):\n",
    "            mdl = RFC(n_estimators=trees, max_depth=depth).fit(feat2.iloc[ktrain,:],labels2.iloc[ktrain,:])\n",
    "            pred = mdl.predict(feat2.iloc[ktest,:])\n",
    "            loss.append(hamming_loss(labels2.iloc[ktest,:], pred))\n",
    "        # Record and report probability\n",
    "        average_loss = np.mean(loss)\n",
    "                   \n",
    "        # Record and report accuracy\n",
    "        print \"Trees:\", trees, \"Depth:\", depth, \"Loss:\", average_loss\n",
    "        \n",
    "        # Update our record of the best parameters seen so far\n",
    "        if average_loss < best_score:\n",
    "            best_score = average_loss\n",
    "            best_trees = trees\n",
    "            best_depth = depth\n",
    "\n",
    "print 'Best number of trees, depth:', best_trees, ',', best_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Go higher in trees and depth\n",
    "\n",
    "# Parameters for tuning a random forest model\n",
    "depths = np.arange(50, 80, 10)\n",
    "\n",
    "# To keep track of the best model\n",
    "best_score = 1\n",
    "\n",
    "kf = KFold(n_splits=3)\n",
    "\n",
    "# Run grid search for model with 5-fold cross validation\n",
    "print '3-fold cross validation:'\n",
    "    \n",
    "for trees in n_trees:\n",
    "    for depth in depths:\n",
    "        loss = []\n",
    "        for ktrain, ktest in kf.split(feat2):\n",
    "            mdl = RFC(n_estimators=160, max_depth=depth, class_weight = 'balanced').fit(feat2.iloc[ktrain,:],labels2.iloc[ktrain,:])\n",
    "            pred = mdl.predict(feat2.iloc[ktest,:])\n",
    "            loss.append(hamming_loss(labels2.iloc[ktest,:], pred))\n",
    "        # Record and report probability\n",
    "        average_loss = np.mean(loss)\n",
    "                   \n",
    "        # Record and report accuracy\n",
    "        print \"Trees:\", trees, \"Depth:\", depth, \"Loss:\", average_loss\n",
    "        \n",
    "        # Update our record of the best parameters seen so far\n",
    "        if average_loss < best_score:\n",
    "            best_score = average_loss\n",
    "            best_trees = trees\n",
    "            best_depth = depth\n",
    "\n",
    "print 'Best number of trees, depth:', best_trees, ',', best_depth"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
